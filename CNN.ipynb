{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Convolutional Neural Network using Python and libraries\n",
    "\n",
    "The goal of this project is to create a CNN and learn it to recognize faces in photos.\n",
    "We will use open-sources pictures libraries to train our model.\n",
    "We will implement the following steps:\n",
    "1. Import all needed libraries\n",
    "2. Import images dataset, normalize it and shape it to fit the NN\n",
    "3. Initialize the NN \n",
    "4. Train the NN with train dataset and check with validation dataset\n",
    "5. Test the NN on test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "### 1.Import all needed libraries\n",
    "\n",
    "We begin by initializing our programing environnement, importing every library needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\maxime dardy\\.conda\\envs\\ml\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: six in c:\\users\\maxime dardy\\.conda\\envs\\ml\\lib\\site-packages (from torchvision) (1.12.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\maxime dardy\\.conda\\envs\\ml\\lib\\site-packages (from torchvision) (6.2.1)\n",
      "Requirement already satisfied: torch in c:\\users\\maxime dardy\\.conda\\envs\\ml\\lib\\site-packages (from torchvision) (1.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\maxime dardy\\.conda\\envs\\ml\\lib\\site-packages (from torchvision) (1.16.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: skorch in c:\\users\\maxime dardy\\.conda\\envs\\ml\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.14.0 in c:\\users\\maxime dardy\\.conda\\envs\\ml\\lib\\site-packages (from skorch) (4.37.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.1.0 in c:\\users\\maxime dardy\\.conda\\envs\\ml\\lib\\site-packages (from skorch) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in c:\\users\\maxime dardy\\.conda\\envs\\ml\\lib\\site-packages (from skorch) (1.16.5)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.19.1 in c:\\users\\maxime dardy\\.conda\\envs\\ml\\lib\\site-packages (from skorch) (0.21.3)\n",
      "Requirement already satisfied, skipping upgrade: tabulate>=0.7.7 in c:\\users\\maxime dardy\\.conda\\envs\\ml\\lib\\site-packages (from skorch) (0.8.5)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\maxime dardy\\.conda\\envs\\ml\\lib\\site-packages (from scikit-learn>=0.19.1->skorch) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetBinaryClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import images dataset and shape it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the dataset and normalizing it to fit into the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.Resize((36,36)),\n",
    "        transforms.Grayscale(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "        # transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "    ])\n",
    "\n",
    "trainsetTotal = torchvision.datasets.ImageFolder(root='./start_deep/train_images',transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainsetTotal, batch_size=64,\n",
    "                                          shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root='./start_deep/test_images_custom',transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "classes=('non-visage','visage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visage visage non-visage visage visage visage visage visage visage non-visage visage visage non-visage visage visage\n"
     ]
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "data = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(data[0][0:15], nrow = 16))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[data[1][j]] for j in range(15)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialize the NN\n",
    "\n",
    "we create our network and instanciate it using the torch.nn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    #define the architecture of the NN\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        # 1 input chanel as images are in gray nuance\n",
    "        # 6 output channels\n",
    "        # 5x5 square convolution\n",
    "        self.conv1 = nn.Conv2d(1,6,5)\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,20,5)\n",
    "        self.conv3 = nn.Conv2d(20,30,5)\n",
    "        #self.pool2 = nn.MaxPool2d(2,2)\n",
    "        #ad affine operation y = Wx + b\n",
    "        #correspond to the differents layers of the NN\n",
    "        # with W = weight of the neurones and B = bias\n",
    "        #self.fc1 = nn.Linear(20*5*5,200)\n",
    "        self.fc1 = nn.Linear(30*8*8,200)\n",
    "        self.fc2 = nn.Linear(200,80)\n",
    "        self.fc3 = nn.Linear(80,2)\n",
    "    \n",
    "    #define the feed-forward algorithm for the NN\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        #x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = (F.relu(self.conv2(x)))\n",
    "        x = (F.relu(self.conv3(x)))\n",
    "        #x = x.view(-1, 20*5*5)\n",
    "        x = x.view(-1, 30*8*8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the torch wrapper in order to use the skitlearn functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetBinaryClassifier(\n",
    "    module = CNN,\n",
    "    #criterion= nn.CrossEntropyLoss,\n",
    "    lr = 0.001,\n",
    "    optimizer = optim.SGD,\n",
    "    threshold=0.5,\n",
    "    max_epochs = 4,\n",
    "    batch_size =128,\n",
    "    warm_start=True \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create:\n",
    "* the criterion which will calculate the Loss function\n",
    "    in this case we use CrossEntropyLoss: a combination of Softmax and Loss fct\n",
    "* the optimizer which the algorithm used to compute the weight (grad desc, Adam...)\n",
    "    in this case we use Stochastical Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train and validate the NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and validate the NN using skitlearn with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainingFeatures = trainingFeatures.view(-1,1)\n",
    "net.fit(trainingFeatures,trainingLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100 loss: 0.682]\n",
      "[1,   200 loss: 0.682]\n",
      "[1,   300 loss: 0.683]\n",
      "[1,   400 loss: 0.682]\n",
      "[1,   500 loss: 0.682]\n",
      "[1,   600 loss: 0.682]\n",
      "[1,   700 loss: 0.682]\n",
      "[1,   800 loss: 0.682]\n",
      "[1,   900 loss: 0.682]\n",
      "[1,  1000 loss: 0.682]\n",
      "[1,  1100 loss: 0.682]\n",
      "[1,  1200 loss: 0.682]\n",
      "[1,  1300 loss: 0.682]\n",
      "[1,  1400 loss: 0.682]\n",
      "[2,   100 loss: 0.682]\n",
      "[2,   200 loss: 0.682]\n",
      "[2,   300 loss: 0.682]\n",
      "[2,   400 loss: 0.682]\n",
      "[2,   500 loss: 0.682]\n",
      "[2,   600 loss: 0.682]\n",
      "[2,   700 loss: 0.682]\n",
      "[2,   800 loss: 0.682]\n",
      "[2,   900 loss: 0.682]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-151344fe70a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(6): # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        #get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "       # imshow(torchvision.utils.make_grid(inputs[0:10]))\n",
    "       # print(' '.join('%5s' % classes[labels[j]] for j in range(10)))\n",
    "        \n",
    "        #zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward + backward prop + optimizer\n",
    "        outputs = cnn(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i %100 == 99: #print every 100 mini-batches\n",
    "            print('[%d, %5d loss: %.3f]' %\n",
    "                 (epoch +1, i +1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './CNN_2.pth'\n",
    "torch.save(cnn.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CNN:\n\tsize mismatch for fc3.weight: copying a param with shape torch.Size([1, 80]) from checkpoint, the shape in current model is torch.Size([2, 80]).\n\tsize mismatch for fc3.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([2]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-17d6436232fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mPATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./CNN_2.pth'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m    767\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m--> 769\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m    770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_named_members\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_members_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CNN:\n\tsize mismatch for fc3.weight: copying a param with shape torch.Size([1, 80]) from checkpoint, the shape in current model is torch.Size([2, 80]).\n\tsize mismatch for fc3.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([2])."
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "PATH = './CNN_2.pth'\n",
    "cnn.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test the NN on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        imagesTest, labelsTest = data\n",
    "        outputsTest = cnn(imagesTest)\n",
    "        _,predicted = torch.max(outputsTest.data, 1)\n",
    "        total += labelsTest.size(0)\n",
    "        correct += (predicted == labelsTest).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Detect the faces in general images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (<ipython-input-11-e338b03248ee>, line 46)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-e338b03248ee>\"\u001b[1;36m, line \u001b[1;32m46\u001b[0m\n\u001b[1;33m    a = 2\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mTabError\u001b[0m\u001b[1;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": [
    "import imutils\n",
    "import argparse\n",
    "import cv2\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "transformer = transforms.Compose([transforms.Resize(36),\n",
    "                                      transforms.ToTensor(),\n",
    "                                     ])\n",
    "\n",
    "def pyramid(image, scale=1.2, minSize=(36,36)):\n",
    "    yield image\n",
    "\n",
    "    while True:\n",
    "        #compute the new dimensions and resize\n",
    "        w = int(image.shape[1] / scale)\n",
    "        image = imutils.resize(image, width = w)\n",
    "\n",
    "        #if image is small enough stop\n",
    "        if image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "            break\n",
    "\n",
    "        yield image\n",
    "\n",
    "\n",
    "def sliding_window(image, stepSize, windowSize):\n",
    "    #sliding a window across the image\n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        for x in range (0, image.shape[1], stepSize):\n",
    "            #yield the current window\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])\n",
    "\n",
    "\n",
    "image = cv2.imread(\"image.jpg\")\n",
    "(winW, winH) = (36, 36)\n",
    "\n",
    "#loop over the pyramid\n",
    "for (i, resized) in enumerate(pyramid(image)):\n",
    "    # loop over the sliding window for each layer of the pyramid\n",
    "\tfor (x, y, window) in sliding_window(resized, stepSize=15, windowSize=(winW, winH)):\n",
    "\t\t# if the window does not meet our desired window size, ignore it\n",
    "\t\tif window.shape[0] != winH or window.shape[1] != winW:\n",
    "\t\t\tcontinue\n",
    "  \n",
    "\n",
    "\t\ta = 2\n",
    "\t\tROI = resized[y:y+winH, x:x+winW]\n",
    "\t\tROI_grey = cv2.cvtColor(ROI, cv2.COLOR_BGR2GRAY)\n",
    "\t\tPIL_ROI = Image.fromarray(ROI_grey)\n",
    "\t\tROI_tensor = transformer(PIL_ROI).float()\n",
    "\t\tROI_tensor = ROI_tensor.unsqueeze_(0)\n",
    "\t\tisFace = cnn(ROI_tensor)\n",
    "        \n",
    "\t\tif isFace:\n",
    "\t\t\tcv2.rectangle(image, (x, y), (x + winW, y + winH), (0, 255, 0), 2)\n",
    "\t\t\tcv2.imshow(\"Window\", image)\n",
    "\t\t\tcv2.waitKey(1)\n",
    " \n",
    "# \t\tsince we do not have a classifier, we'll just draw the window\n",
    "# \t\tclone = resized.copy()\n",
    "# \t\tcv2.rectangle(clone, (x, y), (x + winW, y + winH), (0, 255, 0), 2)\n",
    "# \t\tcv2.imshow(\"Window\", clone)\n",
    "# \t\tcv2.waitKey(1)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
